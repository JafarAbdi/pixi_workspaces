[project]
authors = ["JafarAbdi <jafar.uruc@gmail.com>"]
channels = ["conda-forge"]
description = "Add a short description here"
name = "llama_ws"
platforms = ["linux-64"]
version = "0.1.0"

[activation.env]
CMAKE_INSTALL_MODE = "SYMLINK"
CMAKE_INSTALL_PREFIX = "$CONDA_PREFIX"
GGML_CUDA_ENABLE_UNIFIED_MEMORY = "1"

[tasks]
configure = { cmd = [
  "cmake",
  "-GNinja",
  "-DCMAKE_EXPORT_COMPILE_COMMANDS=ON",
  "-DCMAKE_BUILD_TYPE=Release",
  "-DLLAMA_CURL=ON",
  "-DCURL_LIBRARY=$CONDA_PREFIX/lib/libcurl.so",
  "-DCURL_INCLUDE_DIR=$CONDA_PREFIX/include",
  "-DCURL_NO_CURL_CMAKE=ON",
  "-DGGML_CUDA=ON",
  "-S",
  "llama.cpp/",
  "-B",
  ".build/",
] }
build = { cmd = "cmake --build .build/", depends-on = ["configure"] }
install = { cmd = "cmake --install .build/ --prefix $CONDA_PREFIX", depends-on = [
  "build",
] }

start-qwen32 = { cmd = [
  "llama-server",
  "-hf",
  "unsloth/Qwen2.5-VL-32B-Instruct-GGUF",
  "-ngl",
  "99",
] }
start-qwen = { cmd = [
  "llama-server",
  "-hf",
  "ggml-org/Qwen2.5-VL-7B-Instruct-GGUF",
  "-ngl",
  "99",
] }
start-smolvlm = { cmd = [
  "llama-server",
  "-hf",
  "ggml-org/SmolVLM2-2.2B-Instruct-GGUF",
  "-ngl",
  "99",
] }
start-smollm3 = { cmd = [
  "llama-server",
  "-hf",
  "ggml-org/SmolLM3-3B-GGUF",
  "-ngl",
  "99",
] }
start = { cmd = ["llama-server", "-hf", "ggml-org/gemma-3-12b-it-GGUF"] }
start-coder = { cmd = [
  "llama-server",
  "--hf-repo",
  "ggml-org/Qwen2.5-Coder-3B-Instruct-Q8_0-GGUF",
  "--hf-file",
  "qwen2.5-coder-3b-instruct-q8_0.gguf",
  "--port",
  "8012",
  "-ngl",
  "99",
  "-fa",
  "-ub",
  "1024",
  "-b",
  "1024",
  "-dt",
  "0.1",
  "--ctx-size",
  "0",
  "--cache-reuse",
  "256",
] }

gguf-gui = "gguf-editor-gui"

[dependencies]
libcurl = ">=8.11.1,<9"
cuda = "12.4.1"
huggingface_hub = ">=0.31.4,<0.32"
transformers = ">=4.51.0,<5"

[pypi-dependencies]
gguf = { path = "llama.cpp/gguf-py", extras = ["gui"] }
fg = "*"
openai = ">=1.79.0, <2"
torch = ">=2.7.0, <3"
torchvision = ">=0.22.0, <0.23"
torchaudio = ">=2.7.0, <3"
num2words = ">=0.5.14, <0.6"
peft = ">=0.15.2, <0.16"
hf-xet = ">=1.1.2, <2"
